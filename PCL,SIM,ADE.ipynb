{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlHr1r7aF6U1"
      },
      "outputs": [],
      "source": [
        "# First, import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define the LSTM model for predictive action by the supervisor\n",
        "class PredictiveModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PredictiveModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])  # Using the last hidden state\n",
        "        return out\n",
        "\n",
        "# Step 2: Define Supervisor and Worker\n",
        "class Supervisor:\n",
        "    def __init__(self):\n",
        "        # Define the LSTM model for action prediction\n",
        "        self.model = PredictiveModel(input_size=4, hidden_size=16, output_size=2)  # Predicting 2 actions (x, y)\n",
        "        self.influence_matrix = np.zeros((10, 10))  # Interaction effect matrix between actions\n",
        "        self.exploration_rate = 1.0  # Initial exploration rate\n",
        "\n",
        "    def predict_action(self, state):\n",
        "        \"\"\" Predict next action for the worker (x, y positions) \"\"\"\n",
        "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "        return self.model(state_tensor).detach().numpy()\n",
        "\n",
        "    def update_influence_matrix(self, action, suggested_action, reward):\n",
        "        \"\"\" Update influence matrix based on action and reward \"\"\"\n",
        "        self.influence_matrix[action, suggested_action] += reward\n",
        "        self.influence_matrix /= np.max(self.influence_matrix)  # Normalize matrix\n",
        "\n",
        "    def adaptive_exploration(self, complexity):\n",
        "        \"\"\" Adjust exploration rate based on environment complexity \"\"\"\n",
        "        self.exploration_rate = max(0.1, self.exploration_rate * np.exp(-complexity * 0.1))\n",
        "        return self.exploration_rate\n",
        "\n",
        "# Step 3: Simulate Worker Actions\n",
        "def simulate_worker_action(supervisor, worker_state, complexity):\n",
        "    \"\"\" Simulate the worker's decision-making process \"\"\"\n",
        "    # Predict the next action using the supervisor model\n",
        "    predicted_action = supervisor.predict_action(worker_state)\n",
        "\n",
        "    # Compute exploration rate based on environmental complexity\n",
        "    exploration_rate = supervisor.adaptive_exploration(complexity)\n",
        "\n",
        "    # Decide whether to explore or exploit\n",
        "    if np.random.rand() < exploration_rate:\n",
        "        # Explore: Random action\n",
        "        action = np.random.choice(10)\n",
        "    else:\n",
        "        # Exploit: Use the predicted action from the model\n",
        "        action = np.argmax(predicted_action)\n",
        "\n",
        "    # Return the action and exploration rate\n",
        "    return action, exploration_rate\n",
        "\n",
        "# Step 4: Visualization Function\n",
        "def plot_influence_matrix(supervisor):\n",
        "    \"\"\" Plot the current influence matrix between actions \"\"\"\n",
        "    plt.imshow(supervisor.influence_matrix, cmap='hot', interpolation='nearest')\n",
        "    plt.title(\"Influence Matrix\")\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "# Step 5: Main Loop to Simulate the Interaction\n",
        "def run_simulation():\n",
        "    supervisor = Supervisor()\n",
        "\n",
        "    # Initial state of the worker: [x_position, y_position, x_velocity, y_velocity]\n",
        "    worker_state = [0.5, 0.5, 1.0, 0.0]\n",
        "\n",
        "    # Simulate for 50 steps\n",
        "    for step in range(50):\n",
        "        # Simulate the worker's action\n",
        "        complexity = np.random.rand()  # Random complexity for each step\n",
        "        action, exploration_rate = simulate_worker_action(supervisor, worker_state, complexity)\n",
        "\n",
        "        # Simulate the reward for the action\n",
        "        reward = np.random.rand() * 0.5  # Random reward between 0 and 0.5\n",
        "\n",
        "        # Update the influence matrix with the action taken by the worker\n",
        "        supervisor.update_influence_matrix(action, action, reward)  # Using action to update matrix\n",
        "\n",
        "        # Print progress\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}: Worker action: {action}, Exploration rate: {exploration_rate:.2f}\")\n",
        "\n",
        "        # Update the worker state (here, we simulate some simple physics)\n",
        "        worker_state = [worker_state[0] + 0.1, worker_state[1] + 0.1, worker_state[2], worker_state[3]]"
      ]
    }
  ]
}